# Проект «Климова-75-63»: Работа с данными, API и EDA

---

## О проекте

Проект объединяет задачи по управлению, обработке и аналитике данных, включая:  
- Формирование и анализ исходного датасета по древесине  
- Очистка, трансформация и сохранение данных  
- Проведение визуального и статистического анализа данных (EDA)  
- Запись данных в базу данных PostgreSQL

---

## Основные задачи

### 1. Формирование исходного датасета
- Сбор и структурирование первичных данных по биомассе  
- Сохранение исходного датасета в формате CSV

### 2. Первичный анализ и очистка данных
- Проверка дубликатов и пропусков  
- Приведение столбцов к нужным типам данных  
- Сохранение очищенных и подготовленных данных

### 3. Работа с API и парсинг
- Получение данных о персонаже "Рик и Морти" через API  
- Обработка и парсинг ответов  
- Скрипт для работы с API: `API_example/API_reader.py`
- Скрипт для работы с парсером: `parse_example/data_parser.py`
- Результаты сохраняются в .JSON

### 4. Обработка и визуализация древесных данных (EDA)
- Загрузка и трансформация исходных данных  
- Исследовательский анализ: графики, статистика, корреляции  
- Использование Jupyter Notebook из папки `notebooks/EDA.ipynb`  
- Сохранение промежуточных результатов в CSV и Parquet


### 5. Работа с базой данных PostgreSQL
- Надёжное и безопасное хранение данных в PostgreSQL  
- Использование `write_to_db.py` (главная ветка) для загрузки данных в таблицу  
- Учётные данные хранятся локально, подгружаются динамически для безопасности

---


## Структура проекта

Klimova-75-63-project/

│

├── data_loader.py        #  Скрипт обработки и загрузки данных о древесине

├── write_to_db.py        #  Скрипт для автоматической записи данных в базу PostgreSQL

│

├── notebooks/            #  Jupyter Notebook для EDA

│   └── EDA.ipynb         #  Разведочный анализ данных

│

├── API_example/          #  Скрипты для персонажей "Рик и Морти" (API)

│   └── API_reader.py     #  Получение и сохранение данных из API

│

├── parse_example/        #  Скрипты для парсера json (BeautifulSoup)

│   └── data_parser.py    #  Парсинг сырых данных

│

├── requirements.txt      #  Список python-зависимостей

└── README.md             #  Описание и инструкции по проекту


---

## Данные

**Исходный деревесный датасет:**  
[Biomass Data](https://drive.google.com/drive/folders/1TOftr_GOVv2wXgeg4S5GTd46YWDHC2Ls?usp=drive_link)


**База данных PostgreSQL:**  
Обработанные данные загружаются в PostgreSQL через  
`write_to_db.py`, используемый в главной ветке.  
Все параметры подключения находятся в локальном безопасном хранилище.

---

### Примеры визуализации и вывода данных

**EDA по биомассе:**

<img width="795" height="620" alt="screenshot" src="https://github.com/user-attachments/assets/345ff719-20e7-4dff-99b9-a32712106360" />

.

.

.

[Расширенная и интерактивная визуализация EDA на nbviewer](https://nbviewer.org/github/aclimova/Klimova-75-63-project/blob/main/notebooks/EDA.ipynb)

.

.

.

**Загрузка данных в DataBase**

<img width="903" height="294" alt="image" src="https://github.com/user-attachments/assets/1518cf2e-3257-4772-a6e2-28bce50bd5c4" />


---


## Быстрый старт

**1. Клонируйте репозиторий:**
 
    git clone <https://github.com/aclimova/Klimova-75-63-project>
    
    cd <Климова-75-63>
    
**2. (Рекомендуется) создайте и активируйте виртуальное окружение:**
 
    Для Windows:

        python -m venv venv
      
        venv\Scripts\activate
        
    Для macOS/Linux:
    
        python3 -m venv venv
       
        source venv/bin/activate
        
**3. Установите зависимости:**
  
    pip install -r requirements.txt
    
**4. Скачайте и подготовьте данные:**
   
    Запустите data_loader.py   для автоматической загрузки и подготовки исходных данных.
    
Все промежуточные датасеты будут сохранены в папке data/.
 
    python data_loader.py


**5. Запустите Jupyter Notebook и проведите EDA:** 
    
    jupyter notebook
   
    Откройте в браузере папку notebooks/, EDA.ipynb и пошагово выполните анализ.

    
**6. Загрузите данные в базу PostgreSQL:**

    python write_to_db.py
   
---

**Примечание:**

- Все настройки и примеры вывода размещены в README.md.

- Для работы используйте Python 3.8 и выше, все библиотеки перечислены в requirements.txt.

- Если встретите ошибки - перепроверьте пути и установленные зависимости.

- Никогда не выкладывайте файл с крэденшалами `creds.db` в публичных репозиториях.
